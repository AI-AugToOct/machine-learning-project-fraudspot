#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Disclaimer : This Script Was Created Using AI , The sole purpose
of this script is to generate synthetic fraudulent Arabic job postings for research and educational purposes only.
it may need further enhancements and modifications to suit specific requirements.

Enhanced Arabic Fraudulent Job Postings Generator

This script generates sophisticated synthetic fraudulent Arabic job postings with
advanced fraud patterns including experience mismatches, suspicious emails,
confidential government entities, and realistic red flags.

Key Features:
- Experience field vs description contradictions
- Personal email patterns (@gmail, @hotmail, etc.)
- Confidential government fraud patterns
- Sophisticated multi-layered fraud indicators

Author: Tuwaiq ML Bootcamp
Version: 3.0.0 - Enhanced
"""

import ast
import csv
import json
import random
from datetime import datetime, timedelta
from typing import Any, Dict, List

import numpy as np
import pandas as pd

# Set random seed for reproducibility
random.seed(42)
np.random.seed(42)

# ============================
# ARABIC FRAUD KEYWORDS
# ============================

ARABIC_FRAUD_KEYWORDS = {
    # Unrealistic Rewards
    'unrealistic_rewards': [
        'Ø±Ø§ØªØ¨ Ø¹Ø§Ù„ÙŠ Ø¬Ø¯Ø§Ù‹',
        'Ø¨Ø¯ÙˆÙ† Ø®Ø¨Ø±Ø©',
        'Ø§Ù„Ø¹Ù…Ù„ Ù…Ù† Ø§Ù„Ù…Ù†Ø²Ù„',
        'ÙØ±ØµØ© Ø°Ù‡Ø¨ÙŠØ©',
        'Ø§ÙƒØ³Ø¨ Ù¨Ù Ù  Ø±ÙŠØ§Ù„ ÙŠÙˆÙ…ÙŠØ§Ù‹',
        'Ø§ÙƒØ³Ø¨ Ù¡Ù Ù Ù  Ø±ÙŠØ§Ù„ ÙŠÙˆÙ…ÙŠØ§Ù‹',
        'Ø¯ÙˆØ§Ù… Ø¬Ø²Ø¦ÙŠ',
        'Ù…ÙƒØ§ÙØ¢Øª Ø´Ù‡Ø±ÙŠØ© Ù…ØºØ±ÙŠØ©',
        'Ø¹Ù…ÙˆÙ„Ø§Øª ÙŠÙˆÙ…ÙŠØ©',
        'Ø±Ø§ØªØ¨ Ù¥Ù Ù Ù Ù  Ø±ÙŠØ§Ù„',
        'Ø¯Ø®Ù„ Ù…Ø¶Ù…ÙˆÙ†',
        'Ø£Ø±Ø¨Ø§Ø­ Ø®ÙŠØ§Ù„ÙŠØ©',
        'Ø«Ø±ÙˆØ© Ø³Ø±ÙŠØ¹Ø©',
        'Ø±Ø§ØªØ¨ Ø¨Ø¯ÙˆÙ† Ø¹Ù…Ù„',
        'Ù…Ø§Ù„ Ø³Ù‡Ù„'
    ],
    
    # Urgency and Pressure
    'urgency_pressure': [
        'Ù…Ø·Ù„ÙˆØ¨ ÙÙˆØ±Ø§',
        'ÙˆØ¸ÙŠÙØ© Ø¹Ø§Ø¬Ù„Ø©',
        'Ø¨Ø¯Ø§ÙŠØ© ÙÙˆØ±ÙŠØ©',
        'Ù…Ù‚Ø§Ø¨Ù„Ø© ÙÙˆØ±ÙŠØ©',
        'Ù„Ù„Ø§Ù†Ø¶Ù…Ø§Ù… Ø§Ù„ÙÙˆØ±ÙŠ',
        'ÙØ±ØµØ© Ù…Ø­Ø¯ÙˆØ¯Ø©',
        'Ø§ØªØµÙ„ Ø§Ù„Ø¢Ù†',
        'Ù„Ø§ ØªÙÙˆØª Ø§Ù„ÙØ±ØµØ©',
        'Ø¢Ø®Ø± Ù…ÙˆØ¹Ø¯ Ø§Ù„ÙŠÙˆÙ…',
        'Ø¹Ø¬Ù„ Ù‚Ø¨Ù„ ÙÙˆØ§Øª Ø§Ù„Ø£ÙˆØ§Ù†',
        'Ù…Ù‚Ø§Ø¹Ø¯ Ù…Ø­Ø¯ÙˆØ¯Ø©',
        'Ø§Ù„ØªØ­Ù‚ ÙÙˆØ±Ø§Ù‹'
    ],
    
    # Unprofessional Communication
    'unprofessional_comm': [
        'Ø§Ù„ØªÙˆØ§ØµÙ„ ÙˆØ§ØªØ³Ø§Ø¨ ÙÙ‚Ø·',
        'Ù…Ù‚Ø§Ø¨Ù„Ø© Ø¹Ø¨Ø± ØªÙŠÙ„ÙŠØ¬Ø±Ø§Ù…',
        'Ø§Ù†Ø¶Ù… Ø¥Ù„Ù‰ Ù‚Ù†Ø§ØªÙ†Ø§',
        'Ø±Ø§Ø³Ù„Ù†Ø§ Ø¹Ù„Ù‰ Ø§Ù„ÙˆØ§ØªØ³Ø§Ø¨',
        'Ù„Ù„ØªÙˆØ§ØµÙ„ Ø¬ÙŠÙ…ÙŠÙ„',
        'Ø§ÙŠÙ…ÙŠÙ„ Ù‡ÙˆØªÙ…ÙŠÙ„',
        'ÙŠØ§Ù‡Ùˆ Ù„Ù„Ù…Ø±Ø§Ø³Ù„Ø©',
        'ÙÙ‚Ø· ÙˆØ§ØªØ³Ø§Ø¨',
        'ØªÙŠÙ„ÙŠØ¬Ø±Ø§Ù… Ù„Ù„ØªÙ‚Ø¯ÙŠÙ…',
        'Ù„Ø§ Ù…Ù‚Ø§Ø¨Ù„Ø§Øª Ø´Ø®ØµÙŠØ©',
    ],
    
    # Money and Data Requests
    'money_data_requests': [
        'Ø±Ø³ÙˆÙ… Ù…Ø³Ø¨Ù‚Ø©',
        'Ø±Ø³ÙˆÙ… Ø±Ù…Ø²ÙŠØ©',
        'Ø±Ø³ÙˆÙ… Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ÙÙŠØ²Ø§',
        'Ø¯ÙØ¹ Ù…Ø¨Ù„Øº Ù…Ø§Ø¯ÙŠ',
        'ØµÙˆØ±Ø© Ø§Ù„Ù‡ÙˆÙŠØ©',
        'Ø±Ù‚Ù… Ø§Ù„Ø¢ÙŠØ¨Ø§Ù†',
        'Ù…Ø¹Ù„ÙˆÙ…Ø§ØªÙƒ Ø§Ù„Ø¨Ù†ÙƒÙŠØ©',
        'Ø±Ø³ÙˆÙ… Ø§Ù„ØªØ¯Ø±ÙŠØ¨',
        'Ù…Ø¨Ù„Øº Ø§Ù„ØªØ£Ù…ÙŠÙ†',
        'Ø±Ø³ÙˆÙ… Ø§Ù„Ø§Ø´ØªØ±Ø§Ùƒ',
        'Ø¯ÙØ¹ Ø¶Ù…Ø§Ù†',
        'Ø±Ø³ÙˆÙ… Ø§Ù„Ø¯ÙˆØ±Ø©'
    ]
}

# ============================
# JOB TITLES AND DESCRIPTIONS
# ============================

ARABIC_JOB_TITLES = [
    'Ù…Ø­Ø§Ø³Ø¨', 'Ø¨Ø§Ø¦Ø¹', 'Ø³ÙƒØ±ØªÙŠØ±', 'Ù…Ù†Ø¯ÙˆØ¨ Ù…Ø¨ÙŠØ¹Ø§Øª', 'Ø®Ø¯Ù…Ø© Ø¹Ù…Ù„Ø§Ø¡', 'Ù…ØµÙ…Ù… Ø¬Ø±Ø§ÙÙŠÙƒ',
    'Ù…Ø·ÙˆØ± ÙˆÙŠØ¨', 'Ù…ØªØ±Ø¬Ù…', 'ÙƒØ§ØªØ¨ Ù…Ø­ØªÙˆÙ‰', 'Ù…Ø³ÙˆÙ‚ Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ', 'Ù…Ø­Ø±Ø±', 'Ù…ØµÙˆØ±',
    'Ø³Ø§Ø¦Ù‚', 'Ø­Ø§Ø±Ø³ Ø£Ù…Ù†', 'Ø¹Ø§Ù…Ù„ Ù†Ø¸Ø§ÙØ©', 'Ù…Ø±Ø§Ù‚Ø¨ ÙƒØ§Ù…ÙŠØ±Ø§Øª', 'Ù…Ø¯Ø®Ù„ Ø¨ÙŠØ§Ù†Ø§Øª',
    'Ø§Ø³ØªÙ‚Ø¨Ø§Ù„', 'Ù…Ø³Ø§Ø¹Ø¯ Ø¥Ø¯Ø§Ø±ÙŠ', 'Ù…ÙˆØ¸Ù Ù…Ø¨ÙŠØ¹Ø§Øª', 'Ù…Ù†Ø¯ÙˆØ¨ ØªÙˆØµÙŠÙ„', 'Ù…Ø´Ø±Ù Ù…Ø¨ÙŠØ¹Ø§Øª',
    'Ù…Ø¯ÙŠØ± Ù…ÙƒØªØ¨', 'Ø£Ø®ØµØ§Ø¦ÙŠ Ù…ÙˆØ§Ø±Ø¯ Ø¨Ø´Ø±ÙŠØ©', 'Ù…Ø­Ù„Ù„ Ù…Ø§Ù„ÙŠ', 'Ù…Ø·ÙˆØ± ØªØ·Ø¨ÙŠÙ‚Ø§Øª'
]

SAUDI_REGIONS = [
    'Ø§Ù„Ø±ÙŠØ§Ø¶', 'Ø§Ù„Ù…Ù†Ø·Ù‚Ø© Ø§Ù„Ø´Ø±Ù‚ÙŠØ©', 'Ù…ÙƒØ© Ø§Ù„Ù…ÙƒØ±Ù…Ø©', 'Ø§Ù„Ù…Ø¯ÙŠÙ†Ø© Ø§Ù„Ù…Ù†ÙˆØ±Ø©',
    'Ø§Ù„Ù‚ØµÙŠÙ…', 'Ø¹Ø³ÙŠØ±', 'ØªØ¨ÙˆÙƒ', 'Ø­Ø§Ø¦Ù„', 'Ø§Ù„Ø­Ø¯ÙˆØ¯ Ø§Ù„Ø´Ù…Ø§Ù„ÙŠØ©', 'Ø¬Ø§Ø²Ø§Ù†',
    'Ù†Ø¬Ø±Ø§Ù†', 'Ø§Ù„Ø¨Ø§Ø­Ø©', 'Ø§Ù„Ø¬ÙˆÙ'
]

SAUDI_CITIES = [
    'AR RIYADH', 'JEDDAH', 'AD DAMMAM', 'MAKKAH', 'AL MADINAH',
    'AT TAIF', 'BURAYDAH', 'TABUK', 'HAIL', 'ABHA',
    'KHOBAR', 'YANBU', 'NAJRAN', 'AL JUBAIL', 'ARAR'
]

COMPANY_TYPES = ['Ø®Ø§Øµ', 'Ø­ÙƒÙˆÙ…ÙŠ', 'ØºÙŠØ± Ø±Ø¨Ø­ÙŠ', 'Ø­ÙƒÙˆÙ…ÙŠ Ø³Ø±ÙŠ']
COMPANY_SIZES = ['ØµØºÙŠØ±Ø© ÙØ¦Ø© Ø£', 'ØµØºÙŠØ±Ø© ÙØ¦Ø© Ø¨', 'Ù…ØªÙˆØ³Ø·Ø© ÙØ¦Ø© Ø£', 'Ù…ØªÙˆØ³Ø·Ø© ÙØ¦Ø© Ø¨', 'ÙƒØ¨ÙŠØ±Ø©']
CONTRACT_TYPES = ['Ø¯ÙˆØ§Ù… ÙƒØ§Ù…Ù„', 'Ø¯ÙˆØ§Ù… Ø¬Ø²Ø¦ÙŠ', 'Ø¹Ù…Ù„ Ø¹Ù† Ø¨Ø¹Ø¯', 'Ø¹Ù‚Ø¯ Ù…Ø¤Ù‚Øª']

# Experience mismatch patterns
EXPERIENCE_MISMATCHES = [
    {"exper": "5 Years", "desc_text": "Ø¨Ø¯ÙˆÙ† Ø®Ø¨Ø±Ø© Ù…Ø·Ù„ÙˆØ¨Ø©", "title_modifier": "Ù„Ù„Ø®Ø±ÙŠØ¬ÙŠÙ† Ø§Ù„Ø¬Ø¯Ø¯"},
    {"exper": "0 Years", "desc_text": "Ø®Ø¨Ø±Ø© Ù„Ø§ ØªÙ‚Ù„ Ø¹Ù† Ù§ Ø³Ù†ÙˆØ§Øª", "title_modifier": "Ø®Ø¨Ø±Ø© Ø¹Ø§Ù„ÙŠØ© Ù…Ø·Ù„ÙˆØ¨Ø©"},
    {"exper": "10 Years", "desc_text": "Ù„Ø§ ØªØ´ØªØ±Ø· Ø®Ø¨Ø±Ø© Ø³Ø§Ø¨Ù‚Ø©", "title_modifier": "Ø¨Ø¯ÙˆÙ† Ø®Ø¨Ø±Ø©"},
    {"exper": "3 Years", "desc_text": "Ù„Ù„Ù…Ø¨ØªØ¯Ø¦ÙŠÙ† ÙÙ‚Ø·", "title_modifier": "Ù…Ø±Ø­Ø¨ Ø¨Ø§Ù„Ø¬Ø¯Ø¯"},
    {"exper": "7 Years", "desc_text": "ÙˆØ¸ÙŠÙØ© Ù„Ù„Ø®Ø±ÙŠØ¬ÙŠÙ† Ø§Ù„Ø¬Ø¯Ø¯", "title_modifier": "ÙØ±ØµØ© Ù„Ù„Ù…Ø¨ØªØ¯Ø¦ÙŠÙ†"},
    {"exper": "2 Years", "desc_text": "Ø®Ø¨Ø±Ø© Ù¡Ù¥ Ø³Ù†Ø© ÙƒØ­Ø¯ Ø£Ø¯Ù†Ù‰", "title_modifier": "ÙƒØ¨Ø§Ø± Ø§Ù„Ù…Ø®ØªØµÙŠÙ†"},
    {"exper": "12 Years", "desc_text": "Ù…Ù†Ø§Ø³Ø¨ Ù„Ù„Ø·Ù„Ø§Ø¨ ÙˆØ§Ù„Ø®Ø±ÙŠØ¬ÙŠÙ†", "title_modifier": "ØªØ¯Ø±ÙŠØ¨ ÙˆØªØ£Ù‡ÙŠÙ„"},
    {"exper": "4 Years", "desc_text": "Ø¨Ø¯ÙˆÙ† Ø£ÙŠ Ù…ØªØ·Ù„Ø¨Ø§Øª Ø®Ø¨Ø±Ø©", "title_modifier": "Ø¹Ù…Ù„ Ø¨Ø³ÙŠØ·"}
]

# Suspicious email patterns
SUSPICIOUS_EMAIL_DOMAINS = ['@gmail.com', '@hotmail.com', '@yahoo.com', '@outlook.com']
EMAIL_ARABIC_REFS = [
    'Ù„Ù„ØªÙˆØ§ØµÙ„ Ø¬ÙŠÙ…ÙŠÙ„ ÙÙ‚Ø·',
    'Ø±Ø§Ø³Ù„Ù†Ø§ Ø¹Ù„Ù‰ Ø§Ù„Ù‡ÙˆØªÙ…ÙŠÙ„', 
    'ÙŠØ§Ù‡Ùˆ Ù„Ù„Ù…Ø±Ø§Ø³Ù„Ø©',
    'Ø£Ø±Ø³Ù„ Ø³ÙŠØ±ØªÙƒ Ø¹Ù„Ù‰ Ø§Ù„Ø¬ÙŠÙ…ÙŠÙ„',
    'Ù„Ù„ØªÙ‚Ø¯ÙŠÙ… Ø§ÙŠÙ…ÙŠÙ„ Ø´Ø®ØµÙŠ',
    'ØªÙˆØ§ØµÙ„ Ù…Ø¹Ù†Ø§ Ø¹Ø¨Ø± Ø§Ù„Ø§ÙŠÙ…ÙŠÙ„ Ø§Ù„Ø´Ø®ØµÙŠ'
]

# ============================
# FRAUD GENERATION FUNCTIONS
# ============================

class EnhancedArabicFraudGenerator:
    """Enhanced generator for creating sophisticated Arabic fraudulent job postings"""
    
    def __init__(self, legitimate_df: pd.DataFrame):
        self.legitimate_df = legitimate_df
        self.fraud_posts = []
        self.confidential_gov_count = 0
        self.experience_mismatch_count = 0
        
    def generate_suspicious_company_name(self, is_confidential_gov: bool = False) -> Dict[str, str]:
        """Generate suspicious company names with special handling for confidential government"""
        
        if is_confidential_gov:
            # Confidential government patterns (major fraud indicator)
            confidential_names = [
                'Ø¬Ù‡Ø© Ø­ÙƒÙˆÙ…ÙŠØ© Ø³Ø±ÙŠØ©',
                'Confidential Government Entity', 
                'Ù…Ø¤Ø³Ø³Ø© Ø­ÙƒÙˆÙ…ÙŠØ© ØºÙŠØ± Ù…Ø¹Ù„Ù†Ø©',
                'Ù‚Ø·Ø§Ø¹ Ø­ÙƒÙˆÙ…ÙŠ Ø³Ø±ÙŠ',
                'ÙˆØ²Ø§Ø±Ø© ØºÙŠØ± Ù…Ø­Ø¯Ø¯Ø©',
                'Ù‡ÙŠØ¦Ø© Ø­ÙƒÙˆÙ…ÙŠØ© Ù…Ø¬Ù‡ÙˆÙ„Ø©',
                'Government Agency - Confidential',
                'Ù…Ø¤Ø³Ø³Ø© Ø¹Ø§Ù…Ø© Ø³Ø±ÙŠØ©',
                'Confidential Government',
                'Ø§Ù„Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø­ÙƒÙˆÙ…ÙŠØ©'
            ]
            
            return {
                "comp_name": random.choice(confidential_names),
                "comp_type": "Ø­ÙƒÙˆÙ…ÙŠ Ø³Ø±ÙŠ",
                "comp_no": "CONFIDENTIAL"
            }
        
        # Regular suspicious patterns
        suspicious_prefixes = [
            'Ø´Ø±ÙƒØ©', 'Ù…Ø¤Ø³Ø³Ø©', 'Ù…ÙƒØªØ¨', 'Ø¯Ø§Ø±', 'Ø¨ÙŠØª', 'Ù…Ø±ÙƒØ²', 'Ù…Ø¹Ù‡Ø¯'
        ]
        
        suspicious_names = [
            'Ø§Ù„Ø«Ø±ÙˆØ© Ø§Ù„Ø³Ø±ÙŠØ¹Ø©', 'Ø§Ù„Ù…Ø§Ù„ Ø§Ù„Ø³Ù‡Ù„', 'Ø§Ù„Ù†Ø¬Ø§Ø­ Ø§Ù„Ù…Ø¶Ù…ÙˆÙ†', 'Ø§Ù„Ø£Ø±Ø¨Ø§Ø­ Ø§Ù„Ø°Ù‡Ø¨ÙŠØ©',
            'Ø§Ù„ÙØ±Øµ Ø§Ù„Ø°Ù‡Ø¨ÙŠØ©', 'Ø§Ù„Ø¯Ø®Ù„ Ø§Ù„Ù…Ø¶Ù…ÙˆÙ†', 'Ø§Ù„Ù†Ø¬Ø§Ø­ Ø§Ù„ÙÙˆØ±ÙŠ', 'Ø§Ù„Ù…ÙƒØ§Ø³Ø¨ Ø§Ù„Ø³Ø±ÙŠØ¹Ø©',
            'Ø§Ù„Ø¹Ù…Ù„ Ø§Ù„Ù…Ù†Ø²Ù„ÙŠ', 'Ø§Ù„Ø±Ø¨Ø­ Ø§Ù„Ø­Ù„Ø§Ù„', 'Ø§Ù„Ø§Ø³ØªØ«Ù…Ø§Ø± Ø§Ù„Ø¢Ù…Ù†', 'Ø§Ù„ØªÙˆØ¸ÙŠÙ Ø§Ù„Ø³Ø±ÙŠØ¹',
            'Ø§Ù„ÙˆØ¸Ø§Ø¦Ù Ø§Ù„Ø°Ù‡Ø¨ÙŠØ©', 'Ø§Ù„Ø¹Ù…Ù„ Ø¹Ù† Ø¨Ø¹Ø¯', 'Ø§Ù„Ø£Ø¹Ù…Ø§Ù„ Ø§Ù„Ù…Ù†Ø²Ù„ÙŠØ©', 'Ø§Ù„Ø±Ø¨Ø­ Ø§Ù„ÙŠÙˆÙ…ÙŠ'
        ]
        
        generic_names = [
            'Ø§Ù„Ø´Ø±ÙƒØ© Ø§Ù„Ø¹Ø§Ù…Ø©', 'Ø§Ù„Ù…Ø¤Ø³Ø³Ø© Ø§Ù„ÙƒØ¨Ø±Ù‰', 'Ø§Ù„Ø´Ø±ÙƒØ© Ø§Ù„Ø¯ÙˆÙ„ÙŠØ©', 'Ø§Ù„Ù…Ø¤Ø³Ø³Ø© Ø§Ù„Ø¹Ø§Ù„Ù…ÙŠØ©',
            'Ø§Ù„Ø´Ø±ÙƒØ© Ø§Ù„Ù…Ø­Ø¯ÙˆØ¯Ø©', 'Ø§Ù„ØªØ¬Ø§Ø±Ø© Ø§Ù„Ø¹Ø§Ù…Ø©', 'Ø§Ù„Ø£Ø¹Ù…Ø§Ù„ Ø§Ù„Ù…ØªÙ†ÙˆØ¹Ø©', 'Ø§Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ø´Ø§Ù…Ù„Ø©'
        ]
        
        if random.random() < 0.4:
            comp_name = f"{random.choice(suspicious_prefixes)} {random.choice(suspicious_names)}"
        else:
            comp_name = f"{random.choice(suspicious_prefixes)} {random.choice(generic_names)}"
        
        return {
            "comp_name": comp_name,
            "comp_type": random.choice(['Ø®Ø§Øµ', 'ØºÙŠØ± Ø±Ø¨Ø­ÙŠ']),
            "comp_no": self.generate_suspicious_contact_info()
        }
    
    
    
    
    def generate_experience_mismatch(self) -> Dict[str, str]:
        """Generate experience field vs description contradictions"""
        mismatch = random.choice(EXPERIENCE_MISMATCHES)
        self.experience_mismatch_count += 1
        return mismatch
    
    def generate_suspicious_email(self) -> str:
        """Generate personal email addresses for fraud posts"""
        username = f"job{random.randint(100, 9999)}"
        domain = random.choice(SUSPICIOUS_EMAIL_DOMAINS)
        return f"{username}{domain}"
    
    def inject_email_in_description(self, description: str, email: str) -> str:
        """Inject personal email into job description"""
        email_templates = [
            f"Ù„Ù„ØªÙ‚Ø¯ÙŠÙ… Ø£Ø±Ø³Ù„ Ø³ÙŠØ±ØªÙƒ Ø¹Ù„Ù‰ {email}",
            f"Ø±Ø§Ø³Ù„Ù†Ø§ Ø¹Ù„Ù‰ {email} Ù„Ù„ØªÙØ§ØµÙŠÙ„", 
            f"ØªÙˆØ§ØµÙ„ Ù…Ø¹Ù†Ø§ Ø¹Ø¨Ø± {email}",
            f"Ù„Ù„Ø§Ø³ØªÙØ³Ø§Ø± {email}"
        ]
        
        # Add email reference to description
        email_ref = random.choice(email_templates)
        return f"{description} {email_ref}"
    
    def generate_suspicious_contact_info(self) -> str:
        """Generate suspicious contact information"""
        suspicious_numbers = [
            '1-999999', '2-888888', '3-777777', '1-123456', '9-999999'
        ]
        return random.choice(suspicious_numbers)
    
    def generate_fraudulent_description(self, fraud_type: str, has_exp_mismatch: bool = False, 
                                         exp_mismatch_text: str = "", has_email: bool = False, 
                                         email: str = "") -> str:
        """Generate fraudulent job description with specific fraud patterns"""
        
        base_descriptions = {
            'high_salary': [
                'Ù†Ø­Ù† Ù†Ù‚Ø¯Ù… Ø±Ø§ØªØ¨ Ø¹Ø§Ù„ÙŠ Ø¬Ø¯Ø§Ù‹ ÙŠØµÙ„ Ø¥Ù„Ù‰ Ù¥Ù Ù Ù Ù  Ø±ÙŠØ§Ù„ Ø´Ù‡Ø±ÙŠØ§Ù‹ Ø¨Ø¯ÙˆÙ† Ø®Ø¨Ø±Ø© Ù…Ø·Ù„ÙˆØ¨Ø©.',
                'ÙØ±ØµØ© Ø°Ù‡Ø¨ÙŠØ© Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø±Ø§ØªØ¨ Ù¤Ù Ù Ù Ù  Ø±ÙŠØ§Ù„ Ù…Ø¹ Ø§Ù„Ø¹Ù…Ù„ Ù…Ù† Ø§Ù„Ù…Ù†Ø²Ù„ ÙÙ‚Ø·.',
                'Ø§ÙƒØ³Ø¨ Ù¡Ù Ù Ù  Ø±ÙŠØ§Ù„ ÙŠÙˆÙ…ÙŠØ§Ù‹ Ù…Ø¹ Ù…ÙƒØ§ÙØ¢Øª Ø´Ù‡Ø±ÙŠØ© Ù…ØºØ±ÙŠØ© Ø¨Ø¯ÙˆÙ† Ø£ÙŠ Ø®Ø¨Ø±Ø© Ø³Ø§Ø¨Ù‚Ø©.',
                'ÙˆØ¸ÙŠÙØ© Ø¨Ø±Ø§ØªØ¨ Ø¹Ø§Ù„ÙŠ Ø¬Ø¯Ø§Ù‹ Ù£Ù¥Ù Ù Ù  Ø±ÙŠØ§Ù„ Ø´Ù‡Ø±ÙŠØ§Ù‹ Ù…Ø¹ Ø¹Ù…ÙˆÙ„Ø§Øª ÙŠÙˆÙ…ÙŠØ© Ø¥Ø¶Ø§ÙÙŠØ©.',
                'Ø¯Ø®Ù„ Ù…Ø¶Ù…ÙˆÙ† ÙŠØµÙ„ Ø¥Ù„Ù‰ Ù¦Ù Ù Ù Ù  Ø±ÙŠØ§Ù„ Ø´Ù‡Ø±ÙŠØ§Ù‹ Ù…Ù† Ø®Ù„Ø§Ù„ Ø¯ÙˆØ§Ù… Ø¬Ø²Ø¦ÙŠ ÙÙ‚Ø·.'
            ],
            
            'urgent': [
                'Ù…Ø·Ù„ÙˆØ¨ ÙÙˆØ±Ø§! ÙˆØ¸ÙŠÙØ© Ø¹Ø§Ø¬Ù„Ø© Ù„Ù„Ø§Ù†Ø¶Ù…Ø§Ù… Ø§Ù„ÙÙˆØ±ÙŠ Ø¨Ø¯Ø§ÙŠØ© ÙÙˆØ±ÙŠØ© Ø§Ù„ÙŠÙˆÙ….',
                'ÙØ±ØµØ© Ù…Ø­Ø¯ÙˆØ¯Ø©! Ù…Ù‚Ø§Ø¨Ù„Ø© ÙÙˆØ±ÙŠØ© Ø§Ù„ÙŠÙˆÙ… - Ù„Ø§ ØªÙÙˆØª Ù‡Ø°Ù‡ Ø§Ù„ÙØ±ØµØ© Ø§Ù„Ø°Ù‡Ø¨ÙŠØ©.',
                'Ø¹Ø¬Ù„ Ù‚Ø¨Ù„ ÙÙˆØ§Øª Ø§Ù„Ø£ÙˆØ§Ù†! Ø¢Ø®Ø± Ù…ÙˆØ¹Ø¯ Ù„Ù„ØªÙ‚Ø¯ÙŠÙ… Ø§Ù„ÙŠÙˆÙ… - Ø§ØªØµÙ„ Ø§Ù„Ø¢Ù†.',
                'Ù…Ù‚Ø§Ø¹Ø¯ Ù…Ø­Ø¯ÙˆØ¯Ø©! Ù„Ù„Ø§Ù†Ø¶Ù…Ø§Ù… Ø§Ù„ÙÙˆØ±ÙŠ - Ø¨Ø¯Ø§ÙŠØ© Ø§Ù„Ø¹Ù…Ù„ ØºØ¯Ø§Ù‹.',
                'ÙˆØ¸ÙŠÙØ© Ø¹Ø§Ø¬Ù„Ø©! Ø§Ù„ØªØ­Ù‚ ÙÙˆØ±Ø§Ù‹ - Ù…Ù‚Ø§Ø¨Ù„Ø© ÙÙˆØ±ÙŠØ© Ø®Ù„Ø§Ù„ Ø³Ø§Ø¹Ø§Øª.'
            ],
            
            'communication': [
                'Ù„Ù„ØªÙ‚Ø¯ÙŠÙ… Ø§Ù„ØªÙˆØ§ØµÙ„ ÙˆØ§ØªØ³Ø§Ø¨ ÙÙ‚Ø· Ø¹Ù„Ù‰ Ø§Ù„Ø±Ù‚Ù… Ø§Ù„Ù…Ø±ÙÙ‚ Ø¨Ø¯ÙˆÙ† Ù…ÙƒØ§Ù„Ù…Ø§Øª.',
                'Ù…Ù‚Ø§Ø¨Ù„Ø© Ø¹Ø¨Ø± ØªÙŠÙ„ÙŠØ¬Ø±Ø§Ù… ÙˆØ§Ù†Ø¶Ù… Ø¥Ù„Ù‰ Ù‚Ù†Ø§ØªÙ†Ø§ Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ØªÙØ§ØµÙŠÙ„ Ø£ÙƒØ«Ø±.',
                'Ø±Ø§Ø³Ù„Ù†Ø§ Ø¹Ù„Ù‰ Ø§Ù„ÙˆØ§ØªØ³Ø§Ø¨ Ø£Ùˆ Ø¬ÙŠÙ…ÙŠÙ„ ÙÙ‚Ø· - Ù„Ø§ Ù†Ù‚Ø¨Ù„ Ø§Ù„ØªÙ‚Ø¯ÙŠÙ… Ø¨Ø·Ø±Ù‚ Ø£Ø®Ø±Ù‰.',
                'Ù„Ù„ØªÙˆØ§ØµÙ„ Ø§ÙŠÙ…ÙŠÙ„ Ù‡ÙˆØªÙ…ÙŠÙ„ Ø£Ùˆ ÙŠØ§Ù‡Ùˆ Ù„Ù„Ù…Ø±Ø§Ø³Ù„Ø© - ÙÙ‚Ø· ÙˆØ§ØªØ³Ø§Ø¨ Ù„Ù„Ù…ØªØ§Ø¨Ø¹Ø©.',
                'ØªÙŠÙ„ÙŠØ¬Ø±Ø§Ù… Ù„Ù„ØªÙ‚Ø¯ÙŠÙ… ÙÙ‚Ø· - Ù„Ø§ Ù…Ù‚Ø§Ø¨Ù„Ø§Øª Ø´Ø®ØµÙŠØ© Ù…Ø·Ù„ÙˆØ¨Ø©.'
            ],
            
            'money_request': [
                'Ù…Ø·Ù„ÙˆØ¨ Ø¯ÙØ¹ Ø±Ø³ÙˆÙ… Ø±Ù…Ø²ÙŠØ© Ù¡Ù Ù  Ø±ÙŠØ§Ù„ ÙƒØ±Ø³ÙˆÙ… Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ÙÙŠØ²Ø§ ÙˆØ§Ù„ØªØ¯Ø±ÙŠØ¨.',
                'ÙŠØ¬Ø¨ Ø¥Ø­Ø¶Ø§Ø± ØµÙˆØ±Ø© Ø§Ù„Ù‡ÙˆÙŠØ© ÙˆØ±Ù‚Ù… Ø§Ù„Ø¢ÙŠØ¨Ø§Ù† ÙˆÙ…Ø¹Ù„ÙˆÙ…Ø§ØªÙƒ Ø§Ù„Ø¨Ù†ÙƒÙŠØ© Ù„Ù„ØªÙ‚Ø¯ÙŠÙ….',
                'Ø±Ø³ÙˆÙ… Ù…Ø³Ø¨Ù‚Ø© Ù¥Ù Ù  Ø±ÙŠØ§Ù„ ÙƒØ±Ø³ÙˆÙ… Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙˆØ¶Ù…Ø§Ù† Ø§Ù„ÙˆØ¸ÙŠÙØ© Ù…Ø¹ Ø§Ø³ØªØ±Ø¯Ø§Ø¯ ÙƒØ§Ù…Ù„.',
                'Ù…Ø·Ù„ÙˆØ¨ Ø¯ÙØ¹ Ù…Ø¨Ù„Øº Ù…Ø§Ø¯ÙŠ Ù¢Ù Ù  Ø±ÙŠØ§Ù„ ÙƒØ±Ø³ÙˆÙ… Ø§Ù„Ø§Ø´ØªØ±Ø§Ùƒ ÙÙŠ Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬.',
                'Ø¯ÙØ¹ Ø¶Ù…Ø§Ù† Ù£Ù Ù  Ø±ÙŠØ§Ù„ ÙƒÙ…Ø¨Ù„Øº Ø§Ù„ØªØ£Ù…ÙŠÙ† - ÙŠØ³ØªØ±Ø¯ Ø¨Ø¹Ø¯ Ø´Ù‡Ø± Ù…Ù† Ø§Ù„Ø¹Ù…Ù„.'
            ],
            
            'confidential_gov': [
                'ÙˆØ¸ÙŠÙØ© Ø­ÙƒÙˆÙ…ÙŠØ© Ø³Ø±ÙŠØ© Ø¨Ø±Ø§ØªØ¨ Ù…Ø±ØªÙØ¹ Ø¬Ø¯Ø§Ù‹ ÙˆÙ…Ø²Ø§ÙŠØ§ Ù…Ù…ÙŠØ²Ø©.',
                'ÙØ±ØµØ© Ø°Ù‡Ø¨ÙŠØ© Ù„Ù„Ø¹Ù…Ù„ ÙÙŠ Ø¬Ù‡Ø© Ø­ÙƒÙˆÙ…ÙŠØ© Ù…Ø±Ù…ÙˆÙ‚Ø© Ø¨Ø±Ø§ØªØ¨ ÙŠØ¨Ø¯Ø£ Ù…Ù† Ù¢Ù Ù Ù Ù  Ø±ÙŠØ§Ù„.',
                'ÙˆØ¸ÙŠÙØ© ÙÙŠ Ù‚Ø·Ø§Ø¹ Ø­ÙƒÙˆÙ…ÙŠ Ø³Ø±ÙŠ - ØªÙØ§ØµÙŠÙ„ Ø£ÙƒØ«Ø± Ø¨Ø¹Ø¯ Ø§Ù„ØªÙˆØ§ØµÙ„.',
                'ÙˆØ¸ÙŠÙØ© Ø­ÙƒÙˆÙ…ÙŠØ© Ù…Ù…ØªØ§Ø²Ø© - Ø§Ø³Ù… Ø§Ù„Ø¬Ù‡Ø© Ø³ÙŠØªÙ… Ø§Ù„Ø§Ø¹Ù„Ø§Ù† Ø¹Ù†Ù‡ Ù„Ø§Ø­Ù‚Ø§Ù‹.',
                'ÙˆØ¸ÙŠÙØ© Ø­Ø³Ø§Ø³Ø© ÙÙŠ Ù‚Ø·Ø§Ø¹ Ø­ÙƒÙˆÙ…ÙŠ Ù…Ù‡Ù… - Ù„Ù„Ø¬Ø§Ø¯ÙŠÙŠÙ† ÙÙ‚Ø·.'
            ]
        }
        
        # Get base description
        description = random.choice(base_descriptions.get(fraud_type, base_descriptions['high_salary']))
        
        # Add experience mismatch text if present
        if has_exp_mismatch and exp_mismatch_text:
            description = f"{description} {exp_mismatch_text}"
        
        # Add email if present 
        if has_email and email:
            description = self.inject_email_in_description(description, email)
        
        return description
    
    def generate_fraudulent_tasks(self, fraud_type: str, has_exp_mismatch: bool = False, exp_text: str = "") -> str:
        """Generate fraudulent job tasks with enhanced patterns"""
        
        task_templates = {
            'high_salary': [
                "Ø§Ù„Ø¹Ù…Ù„ Ù…Ù† Ø§Ù„Ù…Ù†Ø²Ù„ Ø¨Ù…Ø±ÙˆÙ†Ø© ÙƒØ§Ù…Ù„Ø© Ù…Ø¹ Ø±Ø§ØªØ¨ Ø¹Ø§Ù„ÙŠ Ø¬Ø¯Ø§Ù‹ Ù…Ø¶Ù…ÙˆÙ†.",
                "Ù…ÙƒØ§ÙØ¢Øª Ø´Ù‡Ø±ÙŠØ© Ù…ØºØ±ÙŠØ© ÙˆØ¹Ù…ÙˆÙ„Ø§Øª ÙŠÙˆÙ…ÙŠØ© Ø¨Ø¯ÙˆÙ† Ø®Ø¨Ø±Ø© Ù…Ø·Ù„ÙˆØ¨Ø©.",
                "Ø¯Ø®Ù„ Ù…Ø¶Ù…ÙˆÙ† Ù…Ø¹ Ø£Ø±Ø¨Ø§Ø­ Ø®ÙŠØ§Ù„ÙŠØ© Ù…Ù† Ø®Ù„Ø§Ù„ Ø§Ù„Ø¹Ù…Ù„ Ø¹Ù† Ø¨Ø¹Ø¯.",
                "Ø«Ø±ÙˆØ© Ø³Ø±ÙŠØ¹Ø© Ù…Ø¹ Ø±Ø§ØªØ¨ Ø¨Ø¯ÙˆÙ† Ø¹Ù…Ù„ Ø´Ø§Ù‚ - ÙØ±ØµØ© Ø°Ù‡Ø¨ÙŠØ©."
            ],
            
            'urgent': [
                "Ø§Ù„Ø¨Ø¯Ø¡ ÙÙˆØ±Ø§Ù‹ - Ù…Ø·Ù„ÙˆØ¨ Ù„Ù„Ø§Ù†Ø¶Ù…Ø§Ù… Ø§Ù„ÙÙˆØ±ÙŠ Ø§Ù„ÙŠÙˆÙ….",
                "Ù…Ù‚Ø§Ø¨Ù„Ø© ÙÙˆØ±ÙŠØ© Ù…Ø¹ Ø¨Ø¯Ø§ÙŠØ© Ø§Ù„Ø¹Ù…Ù„ Ø®Ù„Ø§Ù„ Ù¢Ù¤ Ø³Ø§Ø¹Ø©.",
                "ÙˆØ¸ÙŠÙØ© Ø¹Ø§Ø¬Ù„Ø© ØªØªØ·Ù„Ø¨ Ø§Ù„ØªØ­Ø§Ù‚Ø§Ù‹ ÙÙˆØ±ÙŠØ§Ù‹ Ø¨Ø¯ÙˆÙ† ØªØ£Ø®ÙŠØ±.",
                "ÙØ±ØµØ© Ù…Ø­Ø¯ÙˆØ¯Ø© - Ø§ØªØµÙ„ Ø§Ù„Ø¢Ù† Ù‚Ø¨Ù„ Ø§Ù†ØªÙ‡Ø§Ø¡ Ø§Ù„Ù…Ù‚Ø§Ø¹Ø¯."
            ],
            
            'communication': [
                "Ø§Ù„ØªÙˆØ§ØµÙ„ Ø¹Ø¨Ø± ÙˆØ§ØªØ³Ø§Ø¨ ÙÙ‚Ø· - Ù„Ø§ Ù…Ù‚Ø§Ø¨Ù„Ø§Øª Ø´Ø®ØµÙŠØ©.",
                "Ù…Ù‚Ø§Ø¨Ù„Ø© Ø¹Ø¨Ø± ØªÙŠÙ„ÙŠØ¬Ø±Ø§Ù… ÙˆØ§Ù†Ø¶Ù… Ù„Ù„Ù‚Ù†Ø§Ø© Ù„Ù„ØªÙØ§ØµÙŠÙ„.",
                "Ø±Ø§Ø³Ù„ Ø¹Ù„Ù‰ Ø¬ÙŠÙ…ÙŠÙ„ Ø£Ùˆ Ù‡ÙˆØªÙ…ÙŠÙ„ - ÙˆØ§ØªØ³Ø§Ø¨ Ù„Ù„Ù…ØªØ§Ø¨Ø¹Ø© Ø§Ù„ÙÙˆØ±ÙŠØ©.",
                "ØªÙŠÙ„ÙŠØ¬Ø±Ø§Ù… Ù„Ù„ØªÙ‚Ø¯ÙŠÙ… - Ù„Ø§ Ø­Ø§Ø¬Ø© Ù„Ø²ÙŠØ§Ø±Ø© Ø§Ù„Ù…ÙƒØªØ¨."
            ],
            
            'money_request': [
                "Ø¯ÙØ¹ Ø±Ø³ÙˆÙ… Ø±Ù…Ø²ÙŠØ© Ù„Ù„ØªØ¯Ø±ÙŠØ¨ ÙˆØ¶Ù…Ø§Ù† Ø§Ù„ÙˆØ¸ÙŠÙØ© Ù…Ø¹ Ø§Ù„Ø§Ø³ØªØ±Ø¯Ø§Ø¯.",
                "Ø¥Ø­Ø¶Ø§Ø± Ø§Ù„Ù‡ÙˆÙŠØ© ÙˆØ§Ù„Ø¢ÙŠØ¨Ø§Ù† ÙˆØ§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø¨Ù†ÙƒÙŠØ© Ù„Ù„ØªÙ‚Ø¯ÙŠÙ….",
                "Ø±Ø³ÙˆÙ… Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ÙÙŠØ²Ø§ ÙˆØ±Ø³ÙˆÙ… Ø§Ù„Ø§Ø´ØªØ±Ø§Ùƒ Ù…Ø·Ù„ÙˆØ¨Ø© Ù…Ø³Ø¨Ù‚Ø§Ù‹.",
                "Ù…Ø¨Ù„Øº Ø§Ù„ØªØ£Ù…ÙŠÙ† Ù…Ø·Ù„ÙˆØ¨ ÙƒØ¶Ù…Ø§Ù† - ÙŠØ³ØªØ±Ø¯ Ø¨Ø¹Ø¯ Ø§Ù„ØªÙˆØ¸ÙŠÙ."
            ],
            
            'confidential_gov': [
                "Ø¹Ù…Ù„ ÙÙŠ Ø¨ÙŠØ¦Ø© Ø­ÙƒÙˆÙ…ÙŠØ© Ù…ØªÙ…ÙŠØ²Ø© Ù…Ø¹ Ù…Ø²Ø§ÙŠØ§ Ø§Ø³ØªØ«Ù†Ø§Ø¦ÙŠØ©.",
                "Ù…Ù‡Ø§Ù… Ø­Ø³Ø§Ø³Ø© ÙˆÙ…Ù‡Ù…Ø© ÙÙŠ Ù‚Ø·Ø§Ø¹ Ø­ÙŠÙˆÙŠ.",
                "Ø±Ø§ØªØ¨ Ù…Ø±ØªÙØ¹ ÙˆØªØ£Ù…ÙŠÙ† Ø´Ø§Ù…Ù„ ÙˆÙ…Ø¹Ø§Ø´ ØªÙ‚Ø§Ø¹Ø¯ÙŠ.",
                "Ø¹Ù…Ù„ ÙÙŠ Ø¨ÙŠØ¦Ø© Ø³Ø±ÙŠØ© - ØªÙØ§ØµÙŠÙ„ Ø£ÙƒØ«Ø± Ø¨Ø¹Ø¯ Ø§Ù„ØªÙˆØ¸ÙŠÙ."
            ]
        }
        
        # Get base tasks
        tasks = task_templates.get(fraud_type, task_templates['high_salary'])
        selected_tasks = random.sample(tasks, min(3, len(tasks)))
        
        # Add experience mismatch text if present
        if has_exp_mismatch and exp_text:
            selected_tasks.append(f"Ù…Ù„Ø§Ø­Ø¸Ø©: {exp_text}")
        
        # Format as list similar to legitimate data
        formatted_tasks = [f"   {task}" for task in selected_tasks]
        formatted_tasks.extend(['  ', '  '])  # Add empty entries like in original data
        
        return str(formatted_tasks)
    
    def generate_suspicious_benefits(self, fraud_type: str) -> str:
        """Generate suspicious benefits"""
        if fraud_type == 'high_salary':
            salary = random.choice(['25000.0', '35000.0', '50000.0', '75000.0', '100000.0'])
        elif fraud_type == 'confidential_gov':
            salary = random.choice(['20000.0', '30000.0', '40000.0', '50000.0'])
        else:
            # Still high but less extreme
            salary = random.choice(['15000.0', '20000.0', '25000.0', '30000.0'])
        
        return f"['Salary', '{salary}']"
    
    def generate_fraudulent_post(self, fraud_type: str, job_index: int) -> Dict[str, Any]:
        """Generate a complete fraudulent job posting with enhanced patterns"""
        
        # Determine if this is a confidential government post (40% chance)
        is_confidential_gov = (fraud_type == 'confidential_gov' or random.random() < 0.4)
        
        # Determine if this post has experience mismatch (60% chance)
        has_exp_mismatch = random.random() < 0.6
        
        # Determine if this post has suspicious email (50% chance) 
        has_email = random.random() < 0.5
        
        # Generate experience mismatch if applicable
        exp_mismatch = None
        if has_exp_mismatch:
            exp_mismatch = self.generate_experience_mismatch()
        
        # Generate suspicious email if applicable
        email = None
        if has_email:
            email = self.generate_suspicious_email()
        
        # Select base job title and add suspicious elements
        base_title = random.choice(ARABIC_JOB_TITLES)
        
        if fraud_type in ['urgent', 'high_salary'] or (exp_mismatch and exp_mismatch['title_modifier']):
            if random.random() < 0.3:
                if exp_mismatch and exp_mismatch['title_modifier']:
                    job_title = f"{exp_mismatch['title_modifier']} - {base_title}"
                else:
                    title_modifiers = ['Ù…Ø·Ù„ÙˆØ¨ ÙÙˆØ±Ø§', 'ÙˆØ¸ÙŠÙØ© Ø¹Ø§Ø¬Ù„Ø©', 'ÙØ±ØµØ© Ø°Ù‡Ø¨ÙŠØ©']
                    job_title = f"{random.choice(title_modifiers)} - {base_title}"
            else:
                job_title = base_title
        else:
            job_title = base_title
        
        # Generate company information
        company_info = self.generate_suspicious_company_name(is_confidential_gov)
        if is_confidential_gov:
            self.confidential_gov_count += 1
        
        # Generate fraudulent post
        fraud_post = {
            'job_title': job_title,
            'job_date': random.choice(['27/05/1444', '28/05/1444', '29/05/1444', '30/05/1444']),
            'job_desc': f"['{self.generate_fraudulent_description(fraud_type, has_exp_mismatch, exp_mismatch['desc_text'] if exp_mismatch else '', has_email, email)}']",
            'job_tasks': self.generate_fraudulent_tasks(fraud_type, has_exp_mismatch, exp_mismatch['desc_text'] if exp_mismatch else ''),
            'comp_name': company_info['comp_name'],
            'comp_no': company_info['comp_no'],
            'comp_type': company_info['comp_type'],
            'comp_size': random.choice(COMPANY_SIZES),
            'eco_activity': 'nan',  # Often missing in fraudulent posts
            'qualif': 'nan',  # Often vague or missing
            'region': random.choice(SAUDI_REGIONS),
            'city': random.choice(SAUDI_CITIES) + '...',
            'benefits': self.generate_suspicious_benefits(fraud_type),
            'contract': random.choice(CONTRACT_TYPES),
            'positions': f"0 / {random.randint(1, 50)}",  # Often inflated numbers
            'job_post_id': f"FRAUD{20220000000000 + job_index}",
            'exper': exp_mismatch['exper'] if exp_mismatch else random.choice(['0 Years', '1 Years', '2 Years']),
            'gender': random.choice(['both', 'M', 'F']),
            'fraudulent': 1  # Mark as fraudulent
        }
        
        return fraud_post
    
    def generate_fraud_dataset(self, num_fraud_posts: int = 530) -> List[Dict[str, Any]]:
        """Generate the complete enhanced fraudulent dataset"""
        
        # Enhanced fraud type distribution with confidential government as primary pattern
        fraud_types = ['confidential_gov', 'high_salary', 'urgent', 'communication', 'money_request']
        type_distribution = [0.4, 0.2, 0.15, 0.15, 0.1]  # 40%, 20%, 15%, 15%, 10%
        
        fraud_posts = []
        
        for i in range(num_fraud_posts):
            # Select fraud type based on distribution
            fraud_type = np.random.choice(fraud_types, p=type_distribution)
            
            # Generate fraudulent post
            fraud_post = self.generate_fraudulent_post(fraud_type, i)
            fraud_posts.append(fraud_post)
        
        return fraud_posts


def integrate_fraud_with_legitimate(legitimate_df: pd.DataFrame, fraud_posts: List[Dict[str, Any]]) -> pd.DataFrame:
    """Integrate fraudulent posts with legitimate data randomly"""
    
    print("Integrating fraudulent posts with legitimate data...")
    
    # Add fraudulent column to legitimate data (all 0s)
    legitimate_df['fraudulent'] = 0
    
    # Convert fraud posts to DataFrame
    fraud_df = pd.DataFrame(fraud_posts)
    
    # Combine datasets
    combined_df = pd.concat([legitimate_df, fraud_df], ignore_index=True)
    
    # Shuffle the entire dataset to randomly distribute fraud posts
    combined_df = combined_df.sample(frac=1, random_state=42).reset_index(drop=True)
    
    return combined_df


def validate_dataset_quality(df: pd.DataFrame, fraud_generator: EnhancedArabicFraudGenerator) -> Dict[str, Any]:
    """Validate the quality and structure of the enhanced generated dataset"""
    
    fraud_posts = df[df['fraudulent'] == 1]
    
    # Count experience mismatches
    exp_mismatch_patterns = ['Ø¨Ø¯ÙˆÙ† Ø®Ø¨Ø±Ø©', 'Ù„Ø§ ØªØ´ØªØ±Ø· Ø®Ø¨Ø±Ø©', 'Ù„Ù„Ø®Ø±ÙŠØ¬ÙŠÙ† Ø§Ù„Ø¬Ø¯Ø¯', 'Ù„Ù„Ù…Ø¨ØªØ¯Ø¦ÙŠÙ†']
    exp_mismatches = 0
    for _, row in fraud_posts.iterrows():
        desc_text = str(row['job_desc']).lower()
        if any(pattern in desc_text for pattern in exp_mismatch_patterns):
            if row['exper'] not in ['0 Years', '1 Years']:
                exp_mismatches += 1
    
    # Count suspicious emails
    email_patterns = ['@gmail', '@hotmail', '@yahoo', '@outlook', 'Ø¬ÙŠÙ…ÙŠÙ„', 'Ù‡ÙˆØªÙ…ÙŠÙ„']
    email_frauds = 0
    for _, row in fraud_posts.iterrows():
        desc_text = str(row['job_desc']).lower()
        if any(pattern in desc_text for pattern in email_patterns):
            email_frauds += 1
    
    # Count confidential government posts
    conf_gov_count = len(fraud_posts[fraud_posts['comp_type'] == 'Ø­ÙƒÙˆÙ…ÙŠ Ø³Ø±ÙŠ'])
    
    validation_results = {
        'total_rows': len(df),
        'legitimate_count': len(df[df['fraudulent'] == 0]),
        'fraudulent_count': len(df[df['fraudulent'] == 1]),
        'fraud_percentage': len(df[df['fraudulent'] == 1]) / len(df) * 100,
        'missing_values': df.isnull().sum().to_dict(),
        'columns': list(df.columns),
        'sample_fraud_titles': fraud_posts['job_title'].head(10).tolist(),
        'fraud_patterns': {
            'confidential_government_count': conf_gov_count,
            'confidential_government_percentage': (conf_gov_count / len(fraud_posts)) * 100,
            'experience_mismatches': exp_mismatches,
            'experience_mismatch_percentage': (exp_mismatches / len(fraud_posts)) * 100,
            'suspicious_emails': email_frauds,
            'suspicious_email_percentage': (email_frauds / len(fraud_posts)) * 100,
            'total_experience_mismatches_generated': fraud_generator.experience_mismatch_count,
            'total_confidential_gov_generated': fraud_generator.confidential_gov_count
        }
    }
    
    return validation_results


def main():
    """Main execution function"""
    
    print("ğŸš€ Starting Arabic Fraudulent Job Postings Generator")
    print("=" * 60)
    
    # Load legitimate data
    print("ğŸ“‚ Loading legitimate job postings...")
    try:
        legitimate_df = pd.read_csv('data/raw/Jadarat_data.csv', encoding='utf-8-sig')
        print(f"âœ… Loaded {len(legitimate_df)} legitimate job postings")
    except Exception as e:
        print(f"âŒ Error loading data: {str(e)}")
        return
    
    # Initialize enhanced fraud generator
    print("\nğŸ”§ Initializing enhanced fraud generator...")
    fraud_generator = EnhancedArabicFraudGenerator(legitimate_df)
    
    # Generate fraudulent posts
    print("ğŸ­ Generating 530 fraudulent job postings...")
    fraud_posts = fraud_generator.generate_fraud_dataset(530)
    print(f"âœ… Generated {len(fraud_posts)} fraudulent posts")
    
    # Display fraud distribution
    fraud_types_count = {}
    for post in fraud_posts:
        # Determine fraud type based on content
        desc = post['job_desc'].lower()
        if 'Ø±Ø§ØªØ¨ Ø¹Ø§Ù„ÙŠ' in desc or '50000' in post['benefits']:
            fraud_type = 'high_salary'
        elif 'Ù…Ø·Ù„ÙˆØ¨ ÙÙˆØ±Ø§' in desc or 'Ø¹Ø§Ø¬Ù„' in desc:
            fraud_type = 'urgent'
        elif 'ÙˆØ§ØªØ³Ø§Ø¨' in desc or 'ØªÙŠÙ„ÙŠØ¬Ø±Ø§Ù…' in desc:
            fraud_type = 'communication'
        elif 'Ø±Ø³ÙˆÙ…' in desc or 'Ø¯ÙØ¹' in desc:
            fraud_type = 'money_request'
        else:
            fraud_type = 'mixed'
        
        fraud_types_count[fraud_type] = fraud_types_count.get(fraud_type, 0) + 1
    
    print("\nğŸ“Š Fraud Types Distribution:")
    for fraud_type, count in fraud_types_count.items():
        percentage = (count / len(fraud_posts)) * 100
        print(f"   {fraud_type}: {count} posts ({percentage:.1f}%)")
    
    # Integrate with legitimate data
    print("\nğŸ”„ Integrating fraud posts with legitimate data...")
    combined_df = integrate_fraud_with_legitimate(legitimate_df, fraud_posts)
    print(f"âœ… Created combined dataset with {len(combined_df)} total posts")
    
    # Validate dataset
    print("\nğŸ” Validating dataset quality...")
    validation_results = validate_dataset_quality(combined_df, fraud_generator)
    
    print("\nğŸ“ˆ Dataset Statistics:")
    print(f"   Total rows: {validation_results['total_rows']:,}")
    print(f"   Legitimate posts: {validation_results['legitimate_count']:,}")
    print(f"   Fraudulent posts: {validation_results['fraudulent_count']:,}")
    print(f"   Fraud percentage: {validation_results['fraud_percentage']:.1f}%")
    
    print("\nğŸš¨ Enhanced Fraud Patterns:")
    patterns = validation_results['fraud_patterns']
    print(f"   Confidential Government: {patterns['confidential_government_count']} ({patterns['confidential_government_percentage']:.1f}%)")
    print(f"   Experience Mismatches: {patterns['experience_mismatches']} ({patterns['experience_mismatch_percentage']:.1f}%)")
    print(f"   Suspicious Emails: {patterns['suspicious_emails']} ({patterns['suspicious_email_percentage']:.1f}%)")
    
    # Save combined dataset
    output_file = 'data/processed/arabic_job_postings_with_fraud.csv'
    print(f"\nğŸ’¾ Saving combined dataset to {output_file}...")
    
    try:
        combined_df.to_csv(output_file, index=False, encoding='utf-8-sig')
        print("âœ… Dataset saved successfully!")
        
        # Save validation report
        validation_file = 'data/processed/fraud_generation_report.json'
        with open(validation_file, 'w', encoding='utf-8') as f:
            json.dump(validation_results, f, ensure_ascii=False, indent=2)
        print(f"âœ… Validation report saved to {validation_file}")
        
    except Exception as e:
        print(f"âŒ Error saving dataset: {str(e)}")
        return
    
    # Display sample fraudulent posts
    print("\nğŸ­ Sample Fraudulent Job Titles:")
    fraud_sample = combined_df[combined_df['fraudulent'] == 1]['job_title'].head(10)
    for i, title in enumerate(fraud_sample, 1):
        print(f"   {i}. {title}")
    
    print("\nğŸ‰ Arabic Fraudulent Job Postings Generation Complete!")
    print("=" * 60)
    
    return combined_df


if __name__ == "__main__":
    # Create necessary directories
    import os
    os.makedirs('data/processed', exist_ok=True)
    
    # Run the main function
    result_df = main()
    
    if result_df is not None:
        print(f"\nğŸ“‹ Final Dataset Shape: {result_df.shape}")
        print("ğŸ”— You can now use this dataset for training fraud detection models!")